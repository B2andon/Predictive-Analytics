---
title: "Week 10: Lab - Using SVM on an Air Quality Dataset "
author: 'Brandon Dora'
date: '3-27-2022'
output: html_document
---

---

# Instructions
Conduct **predictive analytics** on the Air Quality dataset to predict changes in
`ozone` values.You will split the Air Quality dataset into a "**training set**" and
a "**test set**". Use various techniques, such as **Kernel-Based Support Vector Machines** (KSVM), **Support Vector Machines** (SVM), **Linear Modeling** (LM), and **Naive Bayes** (NB). 
Determine which technique is best for the dataset.

Add all of your packages that you use for this homework here in the library chunk.
```{r setup}
setwd("C:/Users/Brandon Dora/Desktop/DataMining")
library(tidyverse)
library(caTools)
library(e1071)
library(kernlab)
library(ggplot2)
library(Metrics)
library(gridExtra)
```

# Step 1: Load the data (0.5 point)

Let's go back and analyze the air quality dataset (we used that dataset previously 
in the visualization lab). Remember to think about how to deal with the NAs in the data. 
Replace NAs with the mean value of the column.

```{r, "Step 1"}
# Write your code below.
air <- data.frame(airquality)
air2 <- na.omit(air)
colSums(air2)
mean(air2$Ozone)
mean(air2$Solar.R)
air <- air %>% tidyr::replace_na(list(Ozone = 42, Solar.R = 185))
```

---

# Step 2: Create train and test data sets (0.5 point)

Using techniques discussed in class (or in the video), create two datasets – 
one for training and one for testing.

```{r, "Step 2"}
# Write your code below.
set.seed(123)
split = sample.split(air$Ozone, SplitRatio = 0.75)
training_set = subset(air, split == TRUE)
test_set = subset(air, split == FALSE)
```

---

# Step 3: Build a model using KSVM and visualize the results (2 points)

## Step 3.1 - Build a model
Using `ksvm()`, create a model to try to predict changes in the `ozone` values. 
You can use all the possible attributes, or select the attributes that you think 
would be the most helpful. Of course, use the training dataset.

```{r, "Step 3.1"}
# Write your code below.
airmodel1 <- ksvm(Ozone ~ ., data = training_set)
airmodel1

```

## Step 3.2 - Test the model and find the RMSE
Test the model using the test dataset and find the **Root Mean Squared Error** (RMSE).
Root Mean Squared Error formula here:  
* 

```{r, "Step 3.2"}
# Write your code below.
model1Predict <- predict(airmodel1, test_set)
model1RSME <- (test_set$Ozone - model1Predict) 
testRMSE <- rmse(test_set$Ozone, model1Predict)
testRMSE
```

## Step 3.3 - Plot the results. 
Use a scatter plot. Have the x-axis represent `Temp`, the y-axis represent `Wind`, 
the point size and color represent the error (as defined by the actual ozone level 
minus the predicted ozone level). It should look similar to this:




```{r, "Step 3.3"}
# Write your code below.
 model1plot <- ggplot(data = test_set, aes(x = Temp, y = Wind)) + geom_point(aes(size = model1RSME, color = model1RSME)) + ggtitle("KSVM Model")
model1plot


```

## Step 3.4 - 1) Compute models 2) test the model using the test dataset and find the RMSE, and 3) plot the results for `svm()` and `lm()` the same way in the prior three steps. 
Use `svm()` from in the `e1071` package and `lm()` from Base R to computer two 
new predictive models. Generate similar charts for each model.

### Step 3.4.1 - Compute model/test the model/plot for `svm()`
```{r, "Step 3.4.1"}
# Write your code below.
airmodel2 <- svm(Ozone ~ Solar.R + Wind + Temp + Month + Day, data = training_set)
airmodel2
model2Predict <- predict(airmodel2, test_set)
model2RSME <- (test_set$Ozone - model2Predict) 
testRMSE2 <- rmse(test_set$Ozone, model2Predict)
testRMSE2


model2plot <- ggplot(data = test_set, aes(x = Temp, y = Wind)) + geom_point(aes(size = model2RSME, color = model2RSME)) + ggtitle("SVM Model")

```

### Step 3.4.2 - Compute model/test the model/plot for `lm()`
```{r, "Step 3.4.2"}
# Write your code below.
airmodel3 <- lm(Ozone ~ Solar.R + Wind + Temp + Month + Day, data = training_set)
model3Predict <- predict(airmodel3, test_set)
model3RSME <- (test_set$Ozone - model3Predict) 
testRMSE3 <- rmse(test_set$Ozone, model3Predict)
testRMSE3

model3plot <- ggplot(data = test_set, aes(x = Temp, y = Wind)) + geom_point(aes(size = model3RSME, color = model3RSME)) + ggtitle("LM Model")

```

## Step 3.5 - Plot all three model results together
Show the results for the KSVM, SVM, and LM models in one window. Use the `grid.arrange()`
function to do this. All three models should be scatterplots. 

```{r, "Step 3.5"}
# Write your code below.
grid.arrange(model1plot, model2plot, model3plot, ncol = 2)

```

---

# Step 4: Create a “goodOzone” variable (1 point)

This variable should be either 0 or 1. It should be 0 if the ozone is below the 
average for all the data observations, and 1 if it is equal to or above the 
average ozone observed. Pay attention to the binary factor variable (goodOzone) so you cannot 
use RMSE for calculating error for models you build using this data. 

```{r, "Step 4"}
# Write your code below.
air$goodOzone <- as.factor(if_else(air$Ozone <= mean(air$Ozone),0,1))
test_set$goodOzone <- as.factor(if_else(test_set$Ozone <= mean(test_set$Ozone),0,1))
training_set$goodOzone <- as.factor(if_else(training_set$Ozone <= mean(training_set$Ozone),0,1))
```

---

# Step 5: Predict "good" and "bad" ozone days. (3 points)
Let's see if we can do a better job predicting “good” and “bad” days.

## Step 5.1 - Build a model 
Using `ksvm()`, create a model to try to predict `goodOzone`. 
You can use all the possible attributes, or select the attributes that you think 
would be the most helpful. Of course, use the training dataset.
```{r, "Step 5.1"}
# Write your code below.
airmodel4 <- ksvm(goodOzone ~ ., data = training_set)

```

## Step 5.2 - Test the model and find the percent of `goodOzone`
Test the model on the test dataset, and compute the percent of “goodOzone” that
was correctly predicted. Do not use RMSE here...
```{r, "Step 5.2"}
# Write your code below.
model4Predict <- predict(airmodel4, test_set)
results4 <- table(model4Predict, test_set$goodOzone)
percentCorrect4 <- (results4[1,1]+results4[2,2])/(results4[1,1]+results4[1,2]+results4[2,1]+results4[2,2])*100
percentCorrect4 <- round(percentCorrect4)
percentCorrect4
#in turn we have our percent correct listed above. 



```

## Step 5.3 - Plot the results
```
# determine the prediction is "correct" or "wrong" for each case,   

# create a new dataframe contains correct, temperature and wind, and goodZone

# change column names
  colnames(Plot_ksvm) <- c("correct","Temp","Wind","goodOzone","Predict")
# plot result using ggplot
```
Use a scatter plot. Have the x-axis represent `Temp`, the y-axis represent 
`Wind`, the shape representing what was predicted (good or bad day), the color 
representing the actual value of `goodOzone` (i.e. if the actual ozone level was
good) and the size represent if the prediction was correct (larger symbols should 
be the observations the model got wrong). The plot should look similar to this:



```{r, "Step 5.3"}
# Write your code below.
# I could not figure out how to do this step for the life of me. I would absolutely love an explanation. Thank you!
newData <- data.frame( air$Temp, air$Wind, air$goodOzone)
```

## Step 5.4 - Compute models and plot the results for ksvm, svm, and nb
Build a model using ksvm, svm, nb functions, and use all other variables to predict.    
Use `svm()` and `naiveBayes()` from in the e1071 package.

### Step 5.4.1 - Build a model using the `ksvm()` function,and use all other variables to predict.
```{r, "Step 5.4.1"}
# Write your code below.
airmodel5 <- ksvm(goodOzone ~ ., data = training_set)

```

### Step 5.4.2 - Test the model: Predict the new values from the test data and save the results as a new object. 
Create a dataframe that contains the exact "goodOzone" value and the predicted "goodOzone".  
Compute the percentage of correct cases
```{r, "Step 5.4.2"}
# Write your code below.
#modelling issue.

```


# Step 5.4.3	Plot the results. 
Determine whether the prediction is "correct" or "wrong" for each case
Plot results using ggplot.
Size representing correct/wrong; color representing actual good/bad day; shape representing predicted good/bad day.
  
```{r, "Step 5.4.3"}
# Write your code below.
#modelling issue.

```


# Step 5.4.4 - Compute models and plot the results for "svm" and "nb" 
Do the same three steps as above for "svm"-- `svm()` and "nb"-- `naiveBayes()`: 
1) build models, 2) test the model, 3) plot the results.

```{r, "Step 5.4.4"}
# Write your code below.

#modelling issue.

```

## Step 5.5 - Plot all three model results together
Show the results for the KSVM, SVM, and NB models in one window. Use the `grid.arrange()`
function to do this. All three models should be scatterplots. 

```{r, "Step 5.5"}
# Write your code below.

#modelling issue.
```


---

# Step 6: Which are the best Models for this data? (2 points)

Review what you have done (pay attention the visualization as well as the RMSE in step 3 
and accuracy calculation in step 5) and state which is the best and why. 
Please show the comparison of those error calculation results from Step 3 and Step 5 here.  

> [ In my opinion, I think that the SVM model is the best representation for this dataset due to it having the lowest RMSE number out of the three, though a close second would be the KSVM model due to it having a very close RMSE value to the SVM model. I was unable to complete a good portion of step 5, sadly so I do not know how the naiveBayes model would look plotted, but referring to the ones I was able to complete, I believe the KSVM model and SVM model work best. I do however like using the LM models. I cannot show the RSME values for step 5, but as for the step 3 values they are as follows.

KSVM = 15.7067~
SVM = 15.5706~
LM = 19.3559~
]

# Step 7: Upload your compiled file. (1 point)
Your compiled file should contain the answers to the questions.
